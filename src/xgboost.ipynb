{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precipitation Forecasting using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we investigate XGBoost (eXtreme Gradient Boosting) as a model to forecast precipitation. XGBoost is an efficient implementation of gradient boosting machines that builds an ensemble of decision trees sequentially. Each tree tries to correct the errors made by the previous trees. Unlike RNNs which maintain internal states, XGBoost treats our time series data as a traditional supervised learning problem where we flatten the temporal sequences into feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Train, Validation, and Test Splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/processed/train_data.csv\")\n",
    "validation_data = pd.read_csv(\"../data/processed/validation_data.csv\")\n",
    "test_data = pd.read_csv(\"../data/processed/test_data.csv\")\n",
    "\n",
    "# Sort splits by location -> YYYY -> DOY to ensure correct time ordering\n",
    "train_data.sort_values(by=[\"location\", \"YYYY\", \"DOY\"], inplace=True)\n",
    "validation_data.sort_values(by=[\"location\", \"YYYY\", \"DOY\"], inplace=True)\n",
    "test_data.sort_values(by=[\"location\", \"YYYY\", \"DOY\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sequences for XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, feature_cols, target_col, seq_length=30):\n",
    "    \"\"\"\n",
    "    Create sequences for time series prediction, grouped by location.\n",
    "    Unlike RNNs which keep the temporal dimension, we flatten the sequences\n",
    "    for XGBoost into a single feature vector.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with time series data\n",
    "    feature_cols (list): List of feature column names\n",
    "    target_col (str): Name of the target column\n",
    "    seq_length (int): Length of sequence to use for prediction\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (X array of shape (n_samples, seq_length * n_features),\n",
    "            y array of shape (n_samples,))\n",
    "    \"\"\"\n",
    "    X_list, y_list = [], []\n",
    "    grouped = df.groupby(\"location\", group_keys=True)\n",
    "    \n",
    "    for loc, loc_df in grouped:\n",
    "        loc_df = loc_df.reset_index(drop=True)\n",
    "        loc_features = loc_df[feature_cols].values\n",
    "        loc_target = loc_df[target_col].values\n",
    "        \n",
    "        for i in range(len(loc_df) - seq_length):\n",
    "            # Flatten the sequence into a single feature vector\n",
    "            sequence = loc_features[i:i + seq_length].flatten()\n",
    "            X_list.append(sequence)\n",
    "            y_list.append(loc_target[i + seq_length])\n",
    "    \n",
    "    return np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Features and Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['2m_temp_max', '2m_temp_mean', '2m_temp_min', '2m_dp_temp_max', '2m_dp_temp_mean', '2m_dp_temp_min', '10m_wind_u', '10m_wind_v', 'fcst_alb', 'lai_high_veg', 'lai_low_veg', 'swe', 'surf_net_solar_rad_max', 'surf_net_solar_rad_mean', 'surf_net_therm_rad_max', 'surf_net_therm_rad_mean', 'surf_press', 'total_et', 'volsw_123', 'volsw_4']\n",
      "Target column: prec\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = [\"location\", \"YYYY\", \"DOY\", \"MM\", \"DD\", \"prec\"]\n",
    "feature_cols = [col for col in train_data.columns if col not in exclude_cols]\n",
    "target_col = \"prec\"\n",
    "\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "print(\"Target column:\", target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequence shape: (1202420, 600) (1202420,)\n",
      "Validation sequence shape: (106720, 600) (106720,)\n",
      "Test sequence shape: (106620, 600) (106620,)\n"
     ]
    }
   ],
   "source": [
    "SEQ_LENGTH = 30\n",
    "X_train, y_train = create_sequences(train_data, feature_cols, target_col, seq_length=SEQ_LENGTH)\n",
    "X_val, y_val = create_sequences(validation_data, feature_cols, target_col, seq_length=SEQ_LENGTH)\n",
    "X_test, y_test = create_sequences(test_data, feature_cols, target_col, seq_length=SEQ_LENGTH)\n",
    "\n",
    "print(\"Train sequence shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation sequence shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test sequence shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Build and Train XGBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create feature names for interpretation\n",
    "feature_names = [f\"{col}_t{i}\" for i in range(SEQ_LENGTH) for col in feature_cols]\n",
    "\n",
    "# Convert to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_names)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=feature_names)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=feature_names)\n",
    "\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # regression task\n",
    "    'eval_metric': ['rmse', 'mae'],   # metrics to evaluate\n",
    "    'max_depth': 6,                   # maximum depth of trees\n",
    "    'learning_rate': 0.01,            # learning rate\n",
    "    'subsample': 0.8,                 # fraction of samples used for tree building\n",
    "    'colsample_bytree': 0.8,          # fraction of features used for tree building\n",
    "    'min_child_weight': 1,            # minimum sum of instance weight in a child\n",
    "}\n",
    "\n",
    "# Train model with early stopping\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amitecc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
